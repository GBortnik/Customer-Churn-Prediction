{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a16a46-9b06-4715-99f2-61241d9727c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.2.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.25.6)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: blinker<2,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: packaging<26,>=20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (8.1.8)\n",
      "Collecting watchdog<7,>=2.1.5\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.23 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.23.5)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2022.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Installing collected packages: watchdog, pydeck, altair, streamlit\n",
      "Successfully installed altair-5.5.0 pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1562c12d-8a2e-4a71-b7b1-462272a9a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "131fc158-c490-4e5c-836e-787bd58512d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit: 1.46.1\n",
      "joblib: 1.2.0\n",
      "pandas: 1.5.3\n",
      "numpy: 1.23.5\n",
      "plotly: 6.1.1\n",
      "sklearn: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"streamlit:\", st.__version__)\n",
    "print(\"joblib:\", joblib.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "818b06d3-5340-4778-801d-73a52b2e6502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt created\n"
     ]
    }
   ],
   "source": [
    "# preparing file for streamlit environment\n",
    "requirements = '''streamlit==1.46.1\n",
    "joblib==1.2.0\n",
    "pandas==1.5.3\n",
    "numpy==1.23.5\n",
    "plotly==6.1.1\n",
    "scikit-learn==1.5.1\n",
    "'''\n",
    "# Save requirements.txt \n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "print(\"requirements.txt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf92b1b-9243-48e2-abb3-d24f4d77e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "# Creating app.py file\n",
    "app = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns\n",
    "    le = LabelEncoder()\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    df = df[preprocessing_info['final_feature_names']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_model_pipeline.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    predictions = (churn_probability >= pipeline['model_info']['threshold']).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=200.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=10000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Make prediction using your pipeline\n",
    "                    result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(app)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2683a8b-a592-439b-b537-4967f00b93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n"
     ]
    }
   ],
   "source": [
    "print('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0163f21-5d7b-4985-befb-ec3f7189f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "debuging_app = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns - FIX: Use consistent LabelEncoder\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            # Use saved encoder if available, otherwise create new one\n",
    "            if 'encoders' in preprocessing_info and col in preprocessing_info['encoders']:\n",
    "                le = preprocessing_info['encoders'][col]\n",
    "                try:\n",
    "                    df[col] = le.transform(df[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If value not seen in training, use most common value\n",
    "                    df[col] = le.transform([le.classes_[0]] * len(df))[0]\n",
    "            else:\n",
    "                # Simple mapping for binary columns\n",
    "                df[col] = df[col].map({'No': 0, 'Yes': 1}).fillna(0)\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values)\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    # Ensure we have all required columns in correct order\n",
    "    df = df.reindex(columns=preprocessing_info['final_feature_names'], fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_model_pipeline.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    predictions = (churn_probability >= pipeline['model_info']['threshold']).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Debug: Show pipeline structure\n",
    "    with st.expander(\"Debug: Pipeline Info\"):\n",
    "        st.write(\"Pipeline keys:\", list(pipeline.keys()) if isinstance(pipeline, dict) else \"Not a dict\")\n",
    "        st.write(\"Pipeline type:\", type(pipeline))\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=500.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=50000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Check if pipeline is a dict with specific structure\n",
    "                    if isinstance(pipeline, dict) and 'predict_function' in pipeline:\n",
    "                        # Use your custom pipeline structure\n",
    "                        result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                    elif isinstance(pipeline, dict) and 'model' in pipeline:\n",
    "                        # Use dictionary structure\n",
    "                        processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                        probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                        \n",
    "                    else:\n",
    "                        # Assume it's a scikit-learn pipeline\n",
    "                        probabilities = pipeline.predict_proba(input_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        # Debug info\n",
    "                        st.write(f\"Debug: Churn probability = {churn_prob:.4f}\")\n",
    "                        st.write(f\"Debug: Prediction = {prediction}\")\n",
    "                        \n",
    "                        # Additional debug for the scaling issue\n",
    "                        if isinstance(pipeline, dict) and 'preprocessing_info' in pipeline:\n",
    "                            st.write(f\"Debug: Monthly charges input = {monthly_charges}\")\n",
    "                            st.write(f\"Debug: Total charges input = {total_charges}\")\n",
    "                            \n",
    "                            # Show processed data\n",
    "                            processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                            st.write(\"Debug: Processed data shape:\", processed_data.shape)\n",
    "                            \n",
    "                            # Show specific columns if they exist\n",
    "                            if 'Monthly Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Monthly Charges = {processed_data['Monthly Charges'].iloc[0]:.4f}\")\n",
    "                            if 'Total Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Total Charges = {processed_data['Total Charges'].iloc[0]:.4f}\")\n",
    "                                \n",
    "                            # Show first few processed features\n",
    "                            st.write(\"Debug: First 10 processed features:\")\n",
    "                            st.write(processed_data.iloc[0, :10].to_dict())\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "                    \n",
    "                    # Debug information\n",
    "                    with st.expander(\"Debug Information\"):\n",
    "                        st.write(\"Input data shape:\", input_data.shape)\n",
    "                        st.write(\"Input data columns:\", list(input_data.columns))\n",
    "                        st.write(\"Input data preview:\")\n",
    "                        st.write(input_data)\n",
    "                        st.write(\"Error details:\", str(e))\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(debuging_app)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beecee64-a5ac-475b-a2c8-2c8d68b1d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "debuging_app2 = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns - FIX: Use consistent LabelEncoder\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            # Use saved encoder if available, otherwise create new one\n",
    "            if 'encoders' in preprocessing_info and col in preprocessing_info['encoders']:\n",
    "                le = preprocessing_info['encoders'][col]\n",
    "                try:\n",
    "                    df[col] = le.transform(df[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If value not seen in training, use most common value\n",
    "                    df[col] = le.transform([le.classes_[0]] * len(df))[0]\n",
    "            else:\n",
    "                # Simple mapping for binary columns\n",
    "                df[col] = df[col].map({'No': 0, 'Yes': 1}).fillna(0)\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values)\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    # Ensure we have all required columns in correct order\n",
    "    df = df.reindex(columns=preprocessing_info['final_feature_names'], fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_complete_model.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = pipeline.get('model_info', {}).get('threshold', 0.5)\n",
    "    predictions = (churn_probability >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Debug: Show pipeline structure\n",
    "    with st.expander(\"Debug: Pipeline Info\"):\n",
    "        st.write(\"Pipeline keys:\", list(pipeline.keys()) if isinstance(pipeline, dict) else \"Not a dict\")\n",
    "        st.write(\"Pipeline type:\", type(pipeline))\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=500.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=50000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Check if pipeline is a dict with specific structure\n",
    "                    if isinstance(pipeline, dict) and 'predict_function' in pipeline:\n",
    "                        # Use your custom pipeline structure\n",
    "                        result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                    elif isinstance(pipeline, dict) and 'model' in pipeline:\n",
    "                        # Use dictionary structure\n",
    "                        processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                        probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                        \n",
    "                    else:\n",
    "                        # Assume it's a scikit-learn pipeline\n",
    "                        probabilities = pipeline.predict_proba(input_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        # Debug info\n",
    "                        st.write(f\"Debug: Churn probability = {churn_prob:.4f}\")\n",
    "                        st.write(f\"Debug: Prediction = {prediction}\")\n",
    "                        \n",
    "                        # Additional debug for the scaling issue\n",
    "                        if isinstance(pipeline, dict) and 'preprocessing_info' in pipeline:\n",
    "                            st.write(f\"Debug: Monthly charges input = {monthly_charges}\")\n",
    "                            st.write(f\"Debug: Total charges input = {total_charges}\")\n",
    "                            \n",
    "                            # Show processed data\n",
    "                            processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                            st.write(\"Debug: Processed data shape:\", processed_data.shape)\n",
    "                            \n",
    "                            # Show specific columns if they exist\n",
    "                            if 'Monthly Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Monthly Charges = {processed_data['Monthly Charges'].iloc[0]:.4f}\")\n",
    "                            if 'Total Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Total Charges = {processed_data['Total Charges'].iloc[0]:.4f}\")\n",
    "                                \n",
    "                            # Show first few processed features\n",
    "                            st.write(\"Debug: First 10 processed features:\")\n",
    "                            st.write(processed_data.iloc[0, :10].to_dict())\n",
    "                            \n",
    "                            # Show ALL processed features to understand the full picture\n",
    "                            with st.expander(\"Debug: All processed features\"):\n",
    "                                st.write(processed_data.iloc[0].to_dict())\n",
    "                                \n",
    "                            # Check if there are any features that might explain this behavior\n",
    "                            st.write(\"Debug: Key features analysis:\")\n",
    "                            feature_dict = processed_data.iloc[0].to_dict()\n",
    "                            \n",
    "                            # Look for contract-related features\n",
    "                            contract_features = [k for k in feature_dict.keys() if 'contract' in k.lower()]\n",
    "                            if contract_features:\n",
    "                                st.write(\"Contract features:\", {k: feature_dict[k] for k in contract_features})\n",
    "                            \n",
    "                            # Look for payment method features\n",
    "                            payment_features = [k for k in feature_dict.keys() if 'payment' in k.lower()]\n",
    "                            if payment_features:\n",
    "                                st.write(\"Payment features:\", {k: feature_dict[k] for k in payment_features})\n",
    "                            \n",
    "                            # Look for internet service features\n",
    "                            internet_features = [k for k in feature_dict.keys() if 'internet' in k.lower()]\n",
    "                            if internet_features:\n",
    "                                st.write(\"Internet features:\", {k: feature_dict[k] for k in internet_features})\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "                    \n",
    "                    # Debug information\n",
    "                    with st.expander(\"Debug Information\"):\n",
    "                        st.write(\"Input data shape:\", input_data.shape)\n",
    "                        st.write(\"Input data columns:\", list(input_data.columns))\n",
    "                        st.write(\"Input data preview:\")\n",
    "                        st.write(input_data)\n",
    "                        st.write(\"Error details:\", str(e))\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(debuging_app2)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef424a2-bee7-4927-86c1-1a629ed5fbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
