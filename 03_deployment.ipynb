{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a16a46-9b06-4715-99f2-61241d9727c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.2.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.25.6)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: blinker<2,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: packaging<26,>=20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (8.1.8)\n",
      "Collecting watchdog<7,>=2.1.5\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.23 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.23.5)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2022.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Installing collected packages: watchdog, pydeck, altair, streamlit\n",
      "Successfully installed altair-5.5.0 pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1562c12d-8a2e-4a71-b7b1-462272a9a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "131fc158-c490-4e5c-836e-787bd58512d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit: 1.46.1\n",
      "joblib: 1.2.0\n",
      "pandas: 1.5.3\n",
      "numpy: 1.23.5\n",
      "plotly: 6.1.1\n",
      "sklearn: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"streamlit:\", st.__version__)\n",
    "print(\"joblib:\", joblib.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "818b06d3-5340-4778-801d-73a52b2e6502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt created\n"
     ]
    }
   ],
   "source": [
    "# preparing file for streamlit environment\n",
    "requirements = '''streamlit==1.46.1\n",
    "joblib==1.2.0\n",
    "pandas==1.5.3\n",
    "numpy==1.23.5\n",
    "plotly==6.1.1\n",
    "scikit-learn==1.5.1\n",
    "'''\n",
    "# Save requirements.txt \n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "print(\"requirements.txt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf92b1b-9243-48e2-abb3-d24f4d77e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "# Creating app.py file\n",
    "app = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns\n",
    "    le = LabelEncoder()\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    df = df[preprocessing_info['final_feature_names']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_model_pipeline.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    predictions = (churn_probability >= pipeline['model_info']['threshold']).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=200.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=10000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Make prediction using your pipeline\n",
    "                    result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(app)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2683a8b-a592-439b-b537-4967f00b93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n"
     ]
    }
   ],
   "source": [
    "print('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0163f21-5d7b-4985-befb-ec3f7189f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "debuging_app = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns - FIX: Use consistent LabelEncoder\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            # Use saved encoder if available, otherwise create new one\n",
    "            if 'encoders' in preprocessing_info and col in preprocessing_info['encoders']:\n",
    "                le = preprocessing_info['encoders'][col]\n",
    "                try:\n",
    "                    df[col] = le.transform(df[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If value not seen in training, use most common value\n",
    "                    df[col] = le.transform([le.classes_[0]] * len(df))[0]\n",
    "            else:\n",
    "                # Simple mapping for binary columns\n",
    "                df[col] = df[col].map({'No': 0, 'Yes': 1}).fillna(0)\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values)\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    # Ensure we have all required columns in correct order\n",
    "    df = df.reindex(columns=preprocessing_info['final_feature_names'], fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_model_pipeline.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    predictions = (churn_probability >= pipeline['model_info']['threshold']).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Debug: Show pipeline structure\n",
    "    with st.expander(\"Debug: Pipeline Info\"):\n",
    "        st.write(\"Pipeline keys:\", list(pipeline.keys()) if isinstance(pipeline, dict) else \"Not a dict\")\n",
    "        st.write(\"Pipeline type:\", type(pipeline))\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=500.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=50000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Check if pipeline is a dict with specific structure\n",
    "                    if isinstance(pipeline, dict) and 'predict_function' in pipeline:\n",
    "                        # Use your custom pipeline structure\n",
    "                        result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                    elif isinstance(pipeline, dict) and 'model' in pipeline:\n",
    "                        # Use dictionary structure\n",
    "                        processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                        probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                        \n",
    "                    else:\n",
    "                        # Assume it's a scikit-learn pipeline\n",
    "                        probabilities = pipeline.predict_proba(input_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        # Debug info\n",
    "                        st.write(f\"Debug: Churn probability = {churn_prob:.4f}\")\n",
    "                        st.write(f\"Debug: Prediction = {prediction}\")\n",
    "                        \n",
    "                        # Additional debug for the scaling issue\n",
    "                        if isinstance(pipeline, dict) and 'preprocessing_info' in pipeline:\n",
    "                            st.write(f\"Debug: Monthly charges input = {monthly_charges}\")\n",
    "                            st.write(f\"Debug: Total charges input = {total_charges}\")\n",
    "                            \n",
    "                            # Show processed data\n",
    "                            processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                            st.write(\"Debug: Processed data shape:\", processed_data.shape)\n",
    "                            \n",
    "                            # Show specific columns if they exist\n",
    "                            if 'Monthly Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Monthly Charges = {processed_data['Monthly Charges'].iloc[0]:.4f}\")\n",
    "                            if 'Total Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Total Charges = {processed_data['Total Charges'].iloc[0]:.4f}\")\n",
    "                                \n",
    "                            # Show first few processed features\n",
    "                            st.write(\"Debug: First 10 processed features:\")\n",
    "                            st.write(processed_data.iloc[0, :10].to_dict())\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "                    \n",
    "                    # Debug information\n",
    "                    with st.expander(\"Debug Information\"):\n",
    "                        st.write(\"Input data shape:\", input_data.shape)\n",
    "                        st.write(\"Input data columns:\", list(input_data.columns))\n",
    "                        st.write(\"Input data preview:\")\n",
    "                        st.write(input_data)\n",
    "                        st.write(\"Error details:\", str(e))\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(debuging_app)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beecee64-a5ac-475b-a2c8-2c8d68b1d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "debuging_app2 = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns - FIX: Use consistent LabelEncoder\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            # Use saved encoder if available, otherwise create new one\n",
    "            if 'encoders' in preprocessing_info and col in preprocessing_info['encoders']:\n",
    "                le = preprocessing_info['encoders'][col]\n",
    "                try:\n",
    "                    df[col] = le.transform(df[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If value not seen in training, use most common value\n",
    "                    df[col] = le.transform([le.classes_[0]] * len(df))[0]\n",
    "            else:\n",
    "                # Simple mapping for binary columns\n",
    "                df[col] = df[col].map({'No': 0, 'Yes': 1}).fillna(0)\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values)\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    # Ensure we have all required columns in correct order\n",
    "    df = df.reindex(columns=preprocessing_info['final_feature_names'], fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_complete_model.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = pipeline.get('model_info', {}).get('threshold', 0.5)\n",
    "    predictions = (churn_probability >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Debug: Show pipeline structure\n",
    "    with st.expander(\"Debug: Pipeline Info\"):\n",
    "        st.write(\"Pipeline keys:\", list(pipeline.keys()) if isinstance(pipeline, dict) else \"Not a dict\")\n",
    "        st.write(\"Pipeline type:\", type(pipeline))\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=500.0, value=50.0)\n",
    "    \n",
    "                # Smart calculation of Total Charges based on Monthly Charges and Tenure\n",
    "                calculated_total = monthly_charges * tenure\n",
    "    \n",
    "                # Allow user to adjust, but default to realistic value\n",
    "                total_charges = st.number_input(\n",
    "                    \"Total Charges ($)\", \n",
    "                    min_value=0.0, \n",
    "                    max_value=50000.0, \n",
    "                    value=calculated_total,\n",
    "                    help=f\"Suggested value based on Monthly Charges × Tenure = ${calculated_total:.2f}\"\n",
    "                )\n",
    "    \n",
    "                # Show warning if values are unrealistic\n",
    "                if total_charges > 0 and monthly_charges > 0 and tenure > 0:\n",
    "                    expected_total = monthly_charges * tenure\n",
    "                    ratio = total_charges / expected_total if expected_total > 0 else 0\n",
    "        \n",
    "                    if ratio < 0.5 or ratio > 2.0:\n",
    "                        st.warning(f\"⚠️ Unrealistic combination! Expected Total Charges ≈ ${expected_total:.2f}\")\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Check if pipeline is a dict with specific structure\n",
    "                    if isinstance(pipeline, dict) and 'predict_function' in pipeline:\n",
    "                        # Use your custom pipeline structure\n",
    "                        result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                    elif isinstance(pipeline, dict) and 'model' in pipeline:\n",
    "                        # Use dictionary structure\n",
    "                        processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                        probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                        \n",
    "                    else:\n",
    "                        # Assume it's a scikit-learn pipeline\n",
    "                        probabilities = pipeline.predict_proba(input_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        # Debug info\n",
    "                        st.write(f\"Debug: Churn probability = {churn_prob:.4f}\")\n",
    "                        st.write(f\"Debug: Prediction = {prediction}\")\n",
    "                        \n",
    "                        # Additional debug for the scaling issue\n",
    "                        if isinstance(pipeline, dict) and 'preprocessing_info' in pipeline:\n",
    "                            st.write(f\"Debug: Monthly charges input = {monthly_charges}\")\n",
    "                            st.write(f\"Debug: Total charges input = {total_charges}\")\n",
    "                            \n",
    "                            # Show processed data\n",
    "                            processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                            st.write(\"Debug: Processed data shape:\", processed_data.shape)\n",
    "                            \n",
    "                            # Show specific columns if they exist\n",
    "                            if 'Monthly Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Monthly Charges = {processed_data['Monthly Charges'].iloc[0]:.4f}\")\n",
    "                            if 'Total Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Total Charges = {processed_data['Total Charges'].iloc[0]:.4f}\")\n",
    "                                \n",
    "                            # Show first few processed features\n",
    "                            st.write(\"Debug: First 10 processed features:\")\n",
    "                            st.write(processed_data.iloc[0, :10].to_dict())\n",
    "                            \n",
    "                            # Show ALL processed features to understand the full picture\n",
    "                            with st.expander(\"Debug: All processed features\"):\n",
    "                                st.write(processed_data.iloc[0].to_dict())\n",
    "                                \n",
    "                            # Check if there are any features that might explain this behavior\n",
    "                            st.write(\"Debug: Key features analysis:\")\n",
    "                            feature_dict = processed_data.iloc[0].to_dict()\n",
    "                            \n",
    "                            # Look for contract-related features\n",
    "                            contract_features = [k for k in feature_dict.keys() if 'contract' in k.lower()]\n",
    "                            if contract_features:\n",
    "                                st.write(\"Contract features:\", {k: feature_dict[k] for k in contract_features})\n",
    "                            \n",
    "                            # Look for payment method features\n",
    "                            payment_features = [k for k in feature_dict.keys() if 'payment' in k.lower()]\n",
    "                            if payment_features:\n",
    "                                st.write(\"Payment features:\", {k: feature_dict[k] for k in payment_features})\n",
    "                            \n",
    "                            # Look for internet service features\n",
    "                            internet_features = [k for k in feature_dict.keys() if 'internet' in k.lower()]\n",
    "                            if internet_features:\n",
    "                                st.write(\"Internet features:\", {k: feature_dict[k] for k in internet_features})\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "                    \n",
    "                    # Debug information\n",
    "                    with st.expander(\"Debug Information\"):\n",
    "                        st.write(\"Input data shape:\", input_data.shape)\n",
    "                        st.write(\"Input data columns:\", list(input_data.columns))\n",
    "                        st.write(\"Input data preview:\")\n",
    "                        st.write(input_data)\n",
    "                        st.write(\"Error details:\", str(e))\n",
    "\n",
    "# Dodaj to do swojej aplikacji Streamlit jako test:\n",
    "\n",
    "if st.button(\"🧪 Test with Realistic Value Combinations\"):\n",
    "    st.write(\"Testing with realistic Monthly Charges vs Total Charges combinations:\")\n",
    "    \n",
    "    # Test realistic combinations\n",
    "    test_combinations = [\n",
    "        # Low Monthly Charges scenarios\n",
    "        {\"monthly\": 25, \"total\": 300, \"tenure\": 12, \"description\": \"Low charges, new customer\"},\n",
    "        {\"monthly\": 35, \"total\": 1050, \"tenure\": 30, \"description\": \"Low charges, long tenure\"},\n",
    "        \n",
    "        # Medium Monthly Charges scenarios  \n",
    "        {\"monthly\": 50, \"total\": 600, \"tenure\": 12, \"description\": \"Medium charges, new customer\"},\n",
    "        {\"monthly\": 65, \"total\": 1950, \"tenure\": 30, \"description\": \"Medium charges, long tenure\"},\n",
    "        \n",
    "        # High Monthly Charges scenarios\n",
    "        {\"monthly\": 85, \"total\": 1020, \"tenure\": 12, \"description\": \"High charges, new customer\"},\n",
    "        {\"monthly\": 100, \"total\": 3000, \"tenure\": 30, \"description\": \"High charges, long tenure\"},\n",
    "        \n",
    "        # Problematic combinations (unrealistic)\n",
    "        {\"monthly\": 100, \"total\": 500, \"tenure\": 12, \"description\": \"HIGH charges but LOW total (unrealistic)\"},\n",
    "        {\"monthly\": 30, \"total\": 5000, \"tenure\": 12, \"description\": \"LOW charges but HIGH total (unrealistic)\"},\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in test_combinations:\n",
    "        test_data = pd.DataFrame({\n",
    "            'Customer ID': ['TEST_001'],\n",
    "            'Senior Citizen': ['No'],\n",
    "            'Partner': ['No'], \n",
    "            'Dependents': ['No'],\n",
    "            'Tenure': [combo[\"tenure\"]],\n",
    "            'Phone Service': ['Yes'],\n",
    "            'Multiple Lines': ['No'],\n",
    "            'Internet Service': ['Fiber optic'],\n",
    "            'Online Security': ['No'],\n",
    "            'Online Backup': ['No'],\n",
    "            'Device Protection': ['No'],\n",
    "            'Tech Support': ['No'],\n",
    "            'Streaming TV': ['No'],\n",
    "            'Streaming Movies': ['No'],\n",
    "            'Paperless Billing': ['Yes'],\n",
    "            'Contract': ['Month-to-month'],\n",
    "            'Payment Method': ['Electronic check'],\n",
    "            'Monthly Charges': [combo[\"monthly\"]],\n",
    "            'Total Charges': [combo[\"total\"]]\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            processed_data = preprocess_new_data(test_data, pipeline['preprocessing_info'])\n",
    "            prob = pipeline['model'].predict_proba(processed_data)[0, 1]\n",
    "            \n",
    "            results.append({\n",
    "                'Description': combo[\"description\"],\n",
    "                'Monthly Charges': combo[\"monthly\"],\n",
    "                'Total Charges': combo[\"total\"],\n",
    "                'Tenure': combo[\"tenure\"],\n",
    "                'Churn Probability': f\"{prob:.3f}\",\n",
    "                'Realistic': \"✅\" if combo[\"monthly\"] * combo[\"tenure\"] * 0.8 <= combo[\"total\"] <= combo[\"monthly\"] * combo[\"tenure\"] * 1.2 else \"❌\"\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error with combination {combo}: {e}\")\n",
    "    \n",
    "    # Display results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    st.dataframe(results_df)\n",
    "    \n",
    "    # Show correlation analysis\n",
    "    st.write(\"### Key Observations:\")\n",
    "    st.write(\"- ✅ = Realistic combination (Total ≈ Monthly × Tenure)\")\n",
    "    st.write(\"- ❌ = Unrealistic combination\")\n",
    "    st.write(\"- Check if unrealistic combinations give strange predictions\")\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(debuging_app2)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00024c15-7f41-4bd9-bbe6-ccd033a00091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created\n"
     ]
    }
   ],
   "source": [
    "debuging_app3 = '''import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Churn Prediction App\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def preprocess_new_data(new_data, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Preprocess new data the same way as train data\n",
    "    \"\"\"\n",
    "    df = new_data.copy()\n",
    "    \n",
    "    # Remove ID cols\n",
    "    df = df.drop(columns=[col for col in preprocessing_info['id_cols'] if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # Label encoding binary columns - FIX: Use consistent LabelEncoder\n",
    "    for col in preprocessing_info['bin_cols']:\n",
    "        if col in df.columns and col != 'Churn':  # exclude target if present\n",
    "            # Use saved encoder if available, otherwise create new one\n",
    "            if 'encoders' in preprocessing_info and col in preprocessing_info['encoders']:\n",
    "                le = preprocessing_info['encoders'][col]\n",
    "                try:\n",
    "                    df[col] = le.transform(df[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If value not seen in training, use most common value\n",
    "                    df[col] = le.transform([le.classes_[0]] * len(df))[0]\n",
    "            else:\n",
    "                # Simple mapping for binary columns\n",
    "                df[col] = df[col].map({'No': 0, 'Yes': 1}).fillna(0)\n",
    "    \n",
    "    # get_dummies for multi-values columns\n",
    "    df = pd.get_dummies(data=df, columns=preprocessing_info['multi_cols'])\n",
    "    \n",
    "    # Make sure we have all dummy columns (add missing ones with 0 values)\n",
    "    for col in preprocessing_info['final_feature_names']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Scaling numerical columns\n",
    "    if preprocessing_info['num_cols']:\n",
    "        scaled_nums = preprocessing_info['scaler'].transform(df[preprocessing_info['num_cols']])\n",
    "        scaled_df = pd.DataFrame(scaled_nums, columns=preprocessing_info['num_cols'], index=df.index)\n",
    "        \n",
    "        # Replace original numerical columns with scaled ones\n",
    "        df = df.drop(columns=preprocessing_info['num_cols'])\n",
    "        df = df.merge(scaled_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    # Ensure we have all required columns in correct order\n",
    "    df = df.reindex(columns=preprocessing_info['final_feature_names'], fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_churn(input_data, pipeline_path='churn_complete_model.joblib'):\n",
    "    \"\"\"\n",
    "    Complete predict function - from raw data to result\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "    \n",
    "    # Predict\n",
    "    probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "    churn_probability = probabilities[:, 1]  # probability of class 1 (churn)\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = pipeline.get('model_info', {}).get('threshold', 0.5)\n",
    "    predictions = (churn_probability >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'churn_probabilities': churn_probability,\n",
    "        'no_churn_probabilities': probabilities[:, 0]\n",
    "    }\n",
    "\n",
    "# Dodaj to do debugowania - sprawdź które features mają największy wpływ:\n",
    "\n",
    "def analyze_feature_impact(input_data, pipeline, feature_to_vary, values_to_test):\n",
    "    \"\"\"Analyze how changing one feature affects prediction\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    base_data = input_data.copy()\n",
    "    \n",
    "    for value in values_to_test:\n",
    "        test_data = base_data.copy()\n",
    "        test_data[feature_to_vary] = [value]\n",
    "        \n",
    "        try:\n",
    "            processed_data = preprocess_new_data(test_data, pipeline['preprocessing_info'])\n",
    "            prob = pipeline['model'].predict_proba(processed_data)[0, 1]\n",
    "            \n",
    "            results.append({\n",
    "                feature_to_vary: value,\n",
    "                'Churn_Probability': prob\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error testing {feature_to_vary}={value}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Feauture impact function\n",
    "if st.button(\"📊 Analyze Feature Impact\"):\n",
    "    base_input = pd.DataFrame({\n",
    "        'Customer ID': ['TEST_001'],\n",
    "        'Senior Citizen': ['No'],\n",
    "        'Partner': ['No'],\n",
    "        'Dependents': ['No'],\n",
    "        'Tenure': [12],\n",
    "        'Phone Service': ['Yes'],\n",
    "        'Multiple Lines': ['No'],\n",
    "        'Internet Service': ['Fiber optic'],\n",
    "        'Online Security': ['No'],\n",
    "        'Online Backup': ['No'],\n",
    "        'Device Protection': ['No'],\n",
    "        'Tech Support': ['No'],\n",
    "        'Streaming TV': ['No'],\n",
    "        'Streaming Movies': ['No'],\n",
    "        'Paperless Billing': ['Yes'],\n",
    "        'Contract': ['Month-to-month'],\n",
    "        'Payment Method': ['Electronic check'],\n",
    "        'Monthly Charges': [50.0],\n",
    "        'Total Charges': [600.0]  # Realistic value\n",
    "    })\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.write(\"**Monthly Charges Impact:**\")\n",
    "        monthly_results = analyze_feature_impact(\n",
    "            base_input, pipeline, 'Monthly Charges', \n",
    "            [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "        )\n",
    "        st.dataframe(monthly_results)\n",
    "    \n",
    "    with col2:\n",
    "        st.write(\"**Tenure Impact:**\")\n",
    "        tenure_results = analyze_feature_impact(\n",
    "            base_input, pipeline, 'Tenure',\n",
    "            [1, 6, 12, 18, 24, 36, 48, 60, 72]\n",
    "        )\n",
    "        st.dataframe(tenure_results)\n",
    "\n",
    "# Load model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load('churn_complete_model.joblib')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found. Please upload churn_complete_model.joblib to your repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"🔮 Customer Churn Prediction\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Load pipeline\n",
    "    pipeline = load_model()\n",
    "    \n",
    "    if pipeline is None:\n",
    "        st.stop()\n",
    "    \n",
    "    # Debug: Show pipeline structure\n",
    "    with st.expander(\"Debug: Pipeline Info\"):\n",
    "        st.write(\"Pipeline keys:\", list(pipeline.keys()) if isinstance(pipeline, dict) else \"Not a dict\")\n",
    "        st.write(\"Pipeline type:\", type(pipeline))\n",
    "    \n",
    "    # Create two columns\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Customer Information\")\n",
    "        \n",
    "        # Create input form\n",
    "        with st.form(\"prediction_form\"):\n",
    "            # Customer demographics\n",
    "            st.write(\"**Demographics**\")\n",
    "            col_demo1, col_demo2 = st.columns(2)\n",
    "            \n",
    "            with col_demo1:\n",
    "                senior_citizen = st.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "                partner = st.selectbox(\"Partner\", [\"No\", \"Yes\"])\n",
    "                dependents = st.selectbox(\"Dependents\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            with col_demo2:\n",
    "                tenure = st.number_input(\"Tenure (months)\", min_value=0, max_value=100, value=12)\n",
    "                phone_service = st.selectbox(\"Phone Service\", [\"No\", \"Yes\"])\n",
    "                multiple_lines = st.selectbox(\"Multiple Lines\", [\"No\", \"Yes\", \"No phone service\"])\n",
    "            \n",
    "            # Services\n",
    "            st.write(\"**Services**\")\n",
    "            col_serv1, col_serv2 = st.columns(2)\n",
    "            \n",
    "            with col_serv1:\n",
    "                internet_service = st.selectbox(\"Internet Service\", [\"DSL\", \"Fiber optic\", \"No\"])\n",
    "                online_security = st.selectbox(\"Online Security\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                online_backup = st.selectbox(\"Online Backup\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                device_protection = st.selectbox(\"Device Protection\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "            \n",
    "            with col_serv2:\n",
    "                tech_support = st.selectbox(\"Tech Support\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_tv = st.selectbox(\"Streaming TV\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                streaming_movies = st.selectbox(\"Streaming Movies\", [\"No\", \"Yes\", \"No internet service\"])\n",
    "                paperless_billing = st.selectbox(\"Paperless Billing\", [\"No\", \"Yes\"])\n",
    "            \n",
    "            # Contract and payment\n",
    "            st.write(\"**Contract & Payment**\")\n",
    "            col_pay1, col_pay2 = st.columns(2)\n",
    "            \n",
    "            with col_pay1:\n",
    "                contract = st.selectbox(\"Contract\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "                payment_method = st.selectbox(\"Payment Method\", \n",
    "                    [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"])\n",
    "            \n",
    "            with col_pay2:\n",
    "                monthly_charges = st.number_input(\"Monthly Charges ($)\", min_value=0.0, max_value=500.0, value=50.0)\n",
    "                total_charges = st.number_input(\"Total Charges ($)\", min_value=0.0, max_value=50000.0, value=500.0)\n",
    "            \n",
    "            # Submit button\n",
    "            submitted = st.form_submit_button(\"🔍 Predict Churn\", use_container_width=True)\n",
    "            \n",
    "            if submitted:\n",
    "                # Create input dataframe\n",
    "                input_data = pd.DataFrame({\n",
    "                    'Customer ID': ['TEST_001'],  # Dummy ID\n",
    "                    'Senior Citizen': [senior_citizen],\n",
    "                    'Partner': [partner],\n",
    "                    'Dependents': [dependents],\n",
    "                    'Tenure': [tenure],\n",
    "                    'Phone Service': [phone_service],\n",
    "                    'Multiple Lines': [multiple_lines],\n",
    "                    'Internet Service': [internet_service],\n",
    "                    'Online Security': [online_security],\n",
    "                    'Online Backup': [online_backup],\n",
    "                    'Device Protection': [device_protection],\n",
    "                    'Tech Support': [tech_support],\n",
    "                    'Streaming TV': [streaming_tv],\n",
    "                    'Streaming Movies': [streaming_movies],\n",
    "                    'Paperless Billing': [paperless_billing],\n",
    "                    'Contract': [contract],\n",
    "                    'Payment Method': [payment_method],\n",
    "                    'Monthly Charges': [monthly_charges],\n",
    "                    'Total Charges': [total_charges]\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    # Check if pipeline is a dict with specific structure\n",
    "                    if isinstance(pipeline, dict) and 'predict_function' in pipeline:\n",
    "                        # Use your custom pipeline structure\n",
    "                        result = pipeline['predict_function'](input_data, 'churn_complete_model.joblib')\n",
    "                        churn_prob = result['churn_probabilities'][0]\n",
    "                        prediction = result['predictions'][0]\n",
    "                        \n",
    "                    elif isinstance(pipeline, dict) and 'model' in pipeline:\n",
    "                        # Use dictionary structure\n",
    "                        processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                        probabilities = pipeline['model'].predict_proba(processed_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                        \n",
    "                    else:\n",
    "                        # Assume it's a scikit-learn pipeline\n",
    "                        probabilities = pipeline.predict_proba(input_data)\n",
    "                        churn_prob = probabilities[0, 1]\n",
    "                        prediction = 1 if churn_prob > 0.5 else 0\n",
    "                    \n",
    "                    # Display results in the second column\n",
    "                    with col2:\n",
    "                        st.subheader(\"Prediction Results\")\n",
    "                        \n",
    "                        # Debug info\n",
    "                        st.write(f\"Debug: Churn probability = {churn_prob:.4f}\")\n",
    "                        st.write(f\"Debug: Prediction = {prediction}\")\n",
    "                        \n",
    "                        # Additional debug for the scaling issue\n",
    "                        if isinstance(pipeline, dict) and 'preprocessing_info' in pipeline:\n",
    "                            st.write(f\"Debug: Monthly charges input = {monthly_charges}\")\n",
    "                            st.write(f\"Debug: Total charges input = {total_charges}\")\n",
    "                            \n",
    "                            # Show processed data\n",
    "                            processed_data = preprocess_new_data(input_data, pipeline['preprocessing_info'])\n",
    "                            st.write(\"Debug: Processed data shape:\", processed_data.shape)\n",
    "                            \n",
    "                            # Show specific columns if they exist\n",
    "                            if 'Monthly Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Monthly Charges = {processed_data['Monthly Charges'].iloc[0]:.4f}\")\n",
    "                            if 'Total Charges' in processed_data.columns:\n",
    "                                st.write(f\"Debug: Processed Total Charges = {processed_data['Total Charges'].iloc[0]:.4f}\")\n",
    "                                \n",
    "                            # Show first few processed features\n",
    "                            st.write(\"Debug: First 10 processed features:\")\n",
    "                            st.write(processed_data.iloc[0, :10].to_dict())\n",
    "                            \n",
    "                            # Show ALL processed features to understand the full picture\n",
    "                            with st.expander(\"Debug: All processed features\"):\n",
    "                                st.write(processed_data.iloc[0].to_dict())\n",
    "                                \n",
    "                            # Check if there are any features that might explain this behavior\n",
    "                            st.write(\"Debug: Key features analysis:\")\n",
    "                            feature_dict = processed_data.iloc[0].to_dict()\n",
    "                            \n",
    "                            # Look for contract-related features\n",
    "                            contract_features = [k for k in feature_dict.keys() if 'contract' in k.lower()]\n",
    "                            if contract_features:\n",
    "                                st.write(\"Contract features:\", {k: feature_dict[k] for k in contract_features})\n",
    "                            \n",
    "                            # Look for payment method features\n",
    "                            payment_features = [k for k in feature_dict.keys() if 'payment' in k.lower()]\n",
    "                            if payment_features:\n",
    "                                st.write(\"Payment features:\", {k: feature_dict[k] for k in payment_features})\n",
    "                            \n",
    "                            # Look for internet service features\n",
    "                            internet_features = [k for k in feature_dict.keys() if 'internet' in k.lower()]\n",
    "                            if internet_features:\n",
    "                                st.write(\"Internet features:\", {k: feature_dict[k] for k in internet_features})\n",
    "                        \n",
    "                        # Show probability\n",
    "                        st.metric(\n",
    "                            label=\"Churn Probability\",\n",
    "                            value=f\"{churn_prob:.1%}\",\n",
    "                            delta=f\"{'High Risk' if churn_prob > 0.5 else 'Low Risk'}\"\n",
    "                        )\n",
    "                        \n",
    "                        # Show prediction\n",
    "                        if prediction == 1:\n",
    "                            st.error(\"🚨 **LIKELY TO CHURN**\")\n",
    "                            st.write(\"This customer has a high probability of churning.\")\n",
    "                        else:\n",
    "                            st.success(\"✅ **LIKELY TO STAY**\")\n",
    "                            st.write(\"This customer has a low probability of churning.\")\n",
    "                        \n",
    "                        # Progress bar\n",
    "                        st.write(\"**Risk Level:**\")\n",
    "                        st.progress(churn_prob)\n",
    "                        \n",
    "                        # Additional insights\n",
    "                        st.write(\"**Key Factors:**\")\n",
    "                        if contract == \"Month-to-month\":\n",
    "                            st.write(\"- Month-to-month contract increases churn risk\")\n",
    "                        if tenure < 12:\n",
    "                            st.write(\"- Low tenure increases churn risk\")\n",
    "                        if monthly_charges > 70:\n",
    "                            st.write(\"- High monthly charges increase churn risk\")\n",
    "                        if internet_service == \"Fiber optic\":\n",
    "                            st.write(\"- Fiber optic service may increase churn risk\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Prediction error: {str(e)}\")\n",
    "                    st.write(\"Please check your model pipeline and input data format.\")\n",
    "                    \n",
    "                    # Debug information\n",
    "                    with st.expander(\"Debug Information\"):\n",
    "                        st.write(\"Input data shape:\", input_data.shape)\n",
    "                        st.write(\"Input data columns:\", list(input_data.columns))\n",
    "                        st.write(\"Input data preview:\")\n",
    "                        st.write(input_data)\n",
    "                        st.write(\"Error details:\", str(e))\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div style='text-align: center; color: #666666;'>\n",
    "            <p>Built with Streamlit | Customer Churn Prediction Model</p>\n",
    "        </div>\n",
    "        \"\"\", \n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save app.py\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(debuging_app3)\n",
    "print(\"app.py created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef424a2-bee7-4927-86c1-1a629ed5fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "churndf = pd.read_csv('CustomerChurn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6aa7a72-a152-4697-914a-2964da81a7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7032.000000\n",
       "mean     2283.300441\n",
       "std      2266.771362\n",
       "min        18.800000\n",
       "25%       401.450000\n",
       "50%      1397.475000\n",
       "75%      3794.737500\n",
       "max      8684.800000\n",
       "Name: Total Charges, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf['Total Charges'] = churndf['Total Charges'].replace(\" \",np.nan)\n",
    "churndf = churndf.dropna(subset=['Total Charges'])\n",
    "churndf['Total Charges'].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07e1114-552d-4494-9560-b90ad0ee64ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LoyaltyID', 'Customer ID', 'Senior Citizen', 'Partner', 'Dependents',\n",
       "       'Tenure', 'Phone Service', 'Multiple Lines', 'Internet Service',\n",
       "       'Online Security', 'Online Backup', 'Device Protection', 'Tech Support',\n",
       "       'Streaming TV', 'Streaming Movies', 'Contract', 'Paperless Billing',\n",
       "       'Payment Method', 'Monthly Charges', 'Total Charges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f5a2bf-51dd-4c2a-94ff-d66b5056467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      29.85\n",
       "1     1889.5\n",
       "2     108.15\n",
       "3    1840.75\n",
       "4     151.65\n",
       "Name: Total Charges, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf['Total Charges'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acaad8a3-a19d-435b-aa1f-9881aa820046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7032.000000\n",
       "mean       64.798208\n",
       "std        30.085974\n",
       "min        18.250000\n",
       "25%        35.587500\n",
       "50%        70.350000\n",
       "75%        89.862500\n",
       "max       118.750000\n",
       "Name: Monthly Charges, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf['Monthly Charges'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999f7b1-c85e-4cac-a260-d2597fb23257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
